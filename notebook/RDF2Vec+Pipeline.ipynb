{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gzip, os, csv\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[10] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "if False: \n",
    "    sc.stop()\n",
    "\n",
    "config = SparkConf()\n",
    "config.setMaster(\"local[10]\")\n",
    "config.set(\"spark.executor.memory\", \"10g\")\n",
    "config.set('spark.driver.memory', '10g')\n",
    "config.set(\"spark.memory.offHeap.enabled\",True)\n",
    "config.set(\"spark.memory.offHeap.size\",\"10g\") \n",
    "sc = SparkContext(conf=config)\n",
    "print (sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTriple(net, source, target, edge):\n",
    "    if source in net:\n",
    "        if  target in net[source]:\n",
    "            net[source][target].add(edge)\n",
    "        else:\n",
    "            net[source][target]= set([edge])\n",
    "    else:\n",
    "        net[source]={}\n",
    "        net[source][target] =set([edge])\n",
    "            \n",
    "def getLinks(net, source):\n",
    "    if source not in net:\n",
    "        return {}\n",
    "    return net[source]\n",
    "\n",
    "def randomWalkUniform(triples, startNode, max_depth=5):\n",
    "    next_node =startNode\n",
    "    path = 'n'+str(startNode)+'->'\n",
    "    for i in range(max_depth):\n",
    "        neighs = getLinks(triples,next_node)\n",
    "        #print (neighs)\n",
    "        if len(neighs) == 0: break\n",
    "        weights = []\n",
    "        queue = []\n",
    "        for neigh in neighs:\n",
    "            for edge in neighs[neigh]:\n",
    "                queue.append((edge,neigh))\n",
    "                weights.append(1.0)\n",
    "        edge, next_node = random.choice(queue)\n",
    "        path = path+ 'e'+str(edge)+'->'\n",
    "        path = path+ 'n'+str(next_node)+'->'\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(folders, filename):\n",
    "    entity2id = {}\n",
    "    relation2id = {}\n",
    "    triples = {}\n",
    "\n",
    "    ent_counter = 0\n",
    "    rel_counter = 0\n",
    "    for dirname in folders:\n",
    "        for fname in os.listdir(dirname):\n",
    "            if not filename in fname: continue\n",
    "            print (fname)\n",
    "            if fname.endswith('.gz'):\n",
    "                kgfile = gzip.open(os.path.join(dirname, fname), mode='rt')\n",
    "            else:\n",
    "                kgfile = open(os.path.join(dirname, fname), mode='rt')\n",
    "                \n",
    "            for line in csv.reader(kgfile, delimiter=' ', quotechar='\"'):\n",
    "                h = line[0]\n",
    "                r = line[1]\n",
    "                t = line[2]\n",
    "\n",
    "                if h in entity2id:\n",
    "                    hid = entity2id[h]\n",
    "                else:\n",
    "                    entity2id[h] = ent_counter\n",
    "                    ent_counter+=1\n",
    "                    hid = entity2id[h]\n",
    "\n",
    "                if t in entity2id:\n",
    "                    tid = entity2id[t]\n",
    "                else:\n",
    "                    entity2id[t] = ent_counter\n",
    "                    ent_counter+=1\n",
    "                    tid = entity2id[t]\n",
    "\n",
    "                if r in relation2id:\n",
    "                    rid = relation2id[r]\n",
    "                else:\n",
    "                    relation2id[r] = rel_counter\n",
    "                    rel_counter+=1\n",
    "                    rid = relation2id[r]\n",
    "                addTriple(triples, hid, tid, rid)\n",
    "            print ('Relation:',rel_counter, ' Entity:',ent_counter)\n",
    "    return entity2id,relation2id,triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foodb.nq\n",
      "Relation: 12  Entity: 92908\n"
     ]
    }
   ],
   "source": [
    "folders = ['../data/rdf/']\n",
    "fileext = '.nq'\n",
    "entity2id, relation2id, triples = preprocess(folders, fileext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of triples 367941\n"
     ]
    }
   ],
   "source": [
    "num_triples=0\n",
    "for source in triples:\n",
    "    for  target in triples[source]:\n",
    "        num_triples+=len(triples[source][target])\n",
    "print ('Number of triples',num_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomNWalkUniform(triples, n, walks, path_depth):\n",
    "    path=[]\n",
    "    for k in range(walks):\n",
    "        walk = randomWalkUniform(triples, n, path_depth)\n",
    "        path.append(walk)\n",
    "    path = list(set(path))\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n100->e5->n100->e5->n100->e7->n92899->\n",
      "n100->e5->n100->e5->n100->e0->n3->\n",
      "n100->e7->n92899->\n",
      "n100->e5->n100->e7->n92899->\n",
      "n100->e6->n84313->\n"
     ]
    }
   ],
   "source": [
    "walks = 5\n",
    "path_depth = 10\n",
    "paths = randomNWalkUniform(triples, 100, walks, path_depth)\n",
    "print('\\n'.join(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = list(entity2id.values())\n",
    "b_triples = sc.broadcast(triples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./walks/randwalks_n200_depth1_pagerank_uniform.txt\n",
      "Time elapsed to generate features: 00:00:17\n",
      "./walks/randwalks_n200_depth2_pagerank_uniform.txt\n",
      "Time elapsed to generate features: 00:00:21\n"
     ]
    }
   ],
   "source": [
    "folder = './walks/'\n",
    "if not os.path.isdir(folder):\n",
    "    os.mkdir(folder)\n",
    "walks = 200\n",
    "maxDepth = 3\n",
    "for path_depth in range(1,maxDepth):\n",
    "    filename = folder+'randwalks_n%d_depth%d_pagerank_uniform.txt'%(walks, path_depth)\n",
    "    print (filename)\n",
    "    start_time =time.time()\n",
    "    rdd = sc.parallelize(entities).flatMap(lambda n: randomNWalkUniform(b_triples.value, n, walks, path_depth))\n",
    "    rdd.saveAsTextFile(filename)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print ('Time elapsed to generate features:',time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname, filename):\n",
    "        self.dirname = dirname\n",
    "        self.filename = filename\n",
    "\n",
    "    def __iter__(self):\n",
    "        print ('Processing ',self.filename)\n",
    "        for subfname in os.listdir(self.dirname):\n",
    "            if not self.filename in subfname: continue\n",
    "            fpath = os.path.join(self.dirname, subfname)\n",
    "            for fname in os.listdir(fpath):\n",
    "                if not 'part' in fname: continue\n",
    "                if '.crc' in fname: continue\n",
    "                try:\n",
    "                    for line in open(os.path.join(fpath, fname), mode='r'):\n",
    "                        line = line.rstrip('\\n')\n",
    "                        words = line.split(\"->\")\n",
    "                        yield words\n",
    "                except Exception:\n",
    "                    print(\"Failed reading file:\")\n",
    "                    print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafilename = './walks/' \n",
    "pattern = 'uniform'\n",
    "sentences = MySentences(datafilename, filename=pattern) # a memory-friendly iterator\n",
    "model = gensim.models.Word2Vec(size=200, workers=5, window=5, sg=1, negative=15, iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  uniform\n",
      "Processing  uniform\n",
      "Processing  uniform\n",
      "Processing  uniform\n",
      "Processing  uniform\n",
      "Processing  uniform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23319263, 42366440)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_vocab(sentences)\n",
    "corpus_count = model.corpus_count\n",
    "model.train(sentences, total_examples=corpus_count, epochs =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save('vectors/w2v_vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2entity = { value:key for key,value in entity2id.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatureVector(model, drugs, id2entity, output): \n",
    "        \n",
    "    fw=open(output,'w')\n",
    "    fw.write(str(len(drugs))+\" 200\\n\")\n",
    "\n",
    "    for id_ in sorted(drugs):\n",
    "        nid = 'n'+str(id_)\n",
    "        if  (nid) not in  model.wv:\n",
    "            #print (nid)\n",
    "            continue\n",
    "        vec = model.wv[nid]\n",
    "        vec = \" \".join(map(str,vec))\n",
    "        #print (id2entity[id_])\n",
    "        fw.write( id2entity[id_]+' '+str(vec)+'\\n')\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = []\n",
    "for e in entity2id.keys():\n",
    "    if e.startswith('<https://foodb.ca/foods/'):\n",
    "        if 'n'+str(entity2id[e]) in model.wv:\n",
    "            foods.append(entity2id[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 7, 9, 11, 14, 17, 19, 21, 23, 25]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foods[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractFeatureVector(model, foods, id2entity, '../data/embedding/rdf2vec_vectors.txt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
